{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Cleaning Using Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Introduction**\n",
    "---\n",
    "Data cleaning is one of the most important steps to take before the analysis process begins. It is the process that can make or mar your analysis. safe to say, a dirty data cannot produce a clean analysis.\n",
    "\n",
    "#### **What is Data Cleaning?**\n",
    "\n",
    "Data cleaning is the process of identifying, correcting or removing errors, inconsistencies , and inaccuracies in data in order to imporve its quality and ensure the data is accurate and reliable for analysis. Here, i choose to use python because of the various libraries and tools that can be used for data cleaning. Stay with me and grab a snack!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data Source** | **Backstory** | **Summary**\n",
    "---\n",
    "This dataset was gotten from kaggle.com, was scrapped off imdb top netflix and tvshows. it contains 9 columns and about 9999 rows. This data is completely raw. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data Cleaning Process** \n",
    "---\n",
    "These are the process i carried out in the course of this project.\n",
    "\n",
    "- Import the libraries \n",
    "- Load the data\n",
    "- Check for Null Values\n",
    "- Drop or Replace Nulls\n",
    "- Check and convert datatype \n",
    "- Check for Duplicates \n",
    "- Drop duplicates\n",
    "- Check for string inconsistency \n",
    "- Check for whitespaces and irrelevant puntuations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **_Importing the basics_**\n",
    "First step is to import the necessary libraries, then import the dataset. \n",
    "here, i am using pandas and numpy as they are the most popular libraries used in cleaning data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, i would import the data to my jupyter \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = r\"C:\\Users\\chhat\\Computer_Code\\movies.csv\"\n",
    "#read the data into the notebook\n",
    "movie_df = pd.read_csv(file_path)\n",
    "#print the dataset\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick summary of the dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the dataset sneak pick\n",
    "movie_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Handling Missing Values_**\n",
    "\n",
    "In the cell above, notice the non-null numbers dropping, that is to show that there are null values in the dataset. so i looked further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first step in my cleaning process, is to get rid of null values. \n",
    "#here we notice a drop in the numbers of non_null, meaning there are null values in there. lets take a look\n",
    "movie_df.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this supports the claim, but lets look inwards to the count of these null cells\n",
    "movie_df.isna().sum()\n",
    "#There were enough Null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us treat them one after the other. \n",
    "#for the year column, we will drop the rows where year is null. \n",
    "\n",
    "movie_df = movie_df.dropna(subset = ['YEAR'])\n",
    "#Drop rows with Null values made more sense for an unbiase analysis. \n",
    "#print the dataset\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the rows with null values have been dropped. \n",
    "#let's take a look\n",
    "movie_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next is the genre column, imagine a movie without a genre classification, it should be dropped to avoid confusion \n",
    "movie_df = movie_df.dropna(subset = ['GENRE'])\n",
    "#print the dataset\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so let's check\n",
    "movie_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next is the rating column. \n",
    "#Rating column can be replaced with the average rating in the column. \n",
    "movie_df['RATING'].fillna(movie_df['RATING'].mean(), inplace = True)\n",
    "#hit with a warning error.\n",
    "#print dataset \n",
    "movie_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got hit with the setting with copy warning, i got upset at this point, until i got help from a senior colleague. then it was suppressed! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, i would round off the column to a 1dp. \n",
    "#I need to fix the warning error before proceeding. \n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df['RATING'] = movie_df['RATING'].round(1)\n",
    "#print the dataset \n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm changes and proceed.\n",
    "movie_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#up to the next column VOTES.i need to replace the null values with the mean value, however there is a problem, the column is a string,\n",
    "#so i might need to convert first before finding the mean value. \n",
    "movie_df['VOTES'] = movie_df['VOTES'].astype(float).astype(int, errors='ignore')\n",
    "#converting directly didnt go through as there were ',' in the values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so with value error, lets try another approach \n",
    "try:\n",
    "    #replace the ',' with ''.\n",
    "    movie_df['VOTES'] = movie_df['VOTES'].str.replace(',' , '').astype(float)\n",
    "except ValueError as e:\n",
    "    #print error if any\n",
    "    print(f'Error: {e}')\n",
    "#print the dataset\n",
    "print(movie_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next, i'd get the mean value and replace the null values with it. \n",
    "movie_df['VOTES'].fillna(movie_df['VOTES'].mean(), inplace = True)\n",
    "#print to show changes\n",
    "movie_df\n",
    "#next, i want to round up to 1dp. \n",
    "movie_df['VOTES'] = movie_df['VOTES'].round(1)\n",
    "#print the dataset\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next is the runtime column \n",
    "movie_df['RunTime'].fillna(movie_df['RunTime'].mean(), inplace = True)\n",
    "#print the dataset\n",
    "movie_df\n",
    "#next, i would round off to 1dp\n",
    "movie_df['RunTime'] = movie_df['RunTime'].round(1)\n",
    "#print the dataset\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next is the gross column\n",
    "movie_df.isna().sum()\n",
    "#there are 8856 null values here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so Gross has so many null values in the column, i would replace the null with ZERO. \n",
    "movie_df['Gross'].fillna(0, inplace = True)\n",
    "movie_df\n",
    "#job is done on that. next i would be changing their data type to the appropriate one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Handling Incorrect Data Types_**\n",
    "\n",
    "It is fine to have wrong data types for each columns. The job here is to convert to the appropriate type, some columns have already been treated in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, let me check the affected columns\n",
    "movie_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the year is in string, it should be changed to the date data type.\n",
    "movie_df['YEAR']\n",
    "#to achieve that, first i must strip the column off any delimiter that is not a digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Chhatra Ram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex helps to filter the values in the columns and ensure they are treated as the condition set.\n",
    "new_date = movie_df['YEAR'].str.replace('[^0-9]', '', regex = True)\n",
    "#print the dataset\n",
    "new_date\n",
    "# there are rows with extra values aside the dates, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim the strings by removing extra digits behind the first 4.\n",
    "trimmed_dates = [date[:4] for date in new_date]\n",
    "# Displaying the trimmed strings\n",
    "for trimmed_date in trimmed_dates:\n",
    "    print(trimmed_date)\n",
    "#replace the values with the year column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the column with the trimmed date values\n",
    "movie_df.loc[:, 'YEAR'] = trimmed_dates\n",
    "#print the dataset\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to double check the column\n",
    "movie_df['YEAR'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next, i will change the datatype to datestamp, ns must be written with datatime64 to do the job\n",
    "movie_df['YEAR'] = movie_df['YEAR'].astype('datetime64[ns]')\n",
    "#print the dataset\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next,the genre column. \n",
    "#let me get the distinct values first.\n",
    "movie_df['GENRE'].unique()\n",
    "#this is to show the extent of the dirty data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df.GENRE.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first i will get rid of the white spaces.\n",
    "movie_df['GENRE'] = movie_df['GENRE'].str.strip()\n",
    "#print the dataset\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i want to spilt the key words into columns \n",
    "#get the unique vales first\n",
    "movie_df['GENRE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i will split the keywords into columns \n",
    "# Split the keywords into separate columns using get_dummies\n",
    "#get_dummies would split the keywords into columns and change it to a categorical data type, where 1 means present and 0 means otherwise\n",
    "genre_df = movie_df['GENRE'].str.get_dummies(', ')\n",
    "#print the new columns dataset\n",
    "genre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the dataframe to a categorical data type.\n",
    "genre_df = genre_df.astype('category')\n",
    "#print the dataset\n",
    "genre_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next, i'll drop the old column and replace it with this new data frame\n",
    "movie_df.drop('GENRE', axis = 1, inplace = True)\n",
    "#print the dataset\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then i would concat the new dataframe to the old dataframe\n",
    "movie_df = pd.concat([movie_df, genre_df], axis=1)\n",
    "#print the dataset after joining the new columns\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A quick look at the table summery\n",
    "movie_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next is the one-line column \n",
    "#trim the whitespaces off \n",
    "movie_df['ONE-LINE'] = movie_df['ONE-LINE'].str.strip()\n",
    "#print the dataset\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for any other irregularities\n",
    "movie_df['ONE-LINE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next,is the stars column\n",
    "#first, get rid of the white spaces \n",
    "movie_df['STARS'] = movie_df['STARS'].str.strip()\n",
    "#print the dataset\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets take a closer look at the column again\n",
    "movie_df['STARS']\n",
    "#i need to replace the ''\\n'' with blanks and also replace the '|' with blank\n",
    "movie_df['STARS'] = movie_df['STARS'].str.replace('\\n', '').str.replace('|', ' ')\n",
    "movie_df['STARS']\n",
    "#okay, this looks better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next, is the gross column, lets take a look\n",
    "movie_df['Gross'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i will change the data type but first, have to strip  these string off.\n",
    "movie_df['Gross'] = movie_df['Gross'].str.replace('$M', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#check for the changes made\n",
    "movie_df['Gross'].nunique()\n",
    "#that did not go as planned, okay would try again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#check for the changes made\n",
    "movie_df['Gross'].unique()\n",
    "#that did not go as planned, okay would try again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df['Gross'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movie_df['Gross'] = pd.to_numeric(movie_df['Gross'], errors='coerce')\n",
    "# Round the 'float_column' to 1 decimal place\n",
    "movie_df['Gross'] = movie_df['Gross'].round(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the values been replaced with NaN, next i would change the NaN to zero.\n",
    "movie_df['Gross']\n",
    "movie_df['Gross'].fillna(0, inplace = True)\n",
    "#print the dataset\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for unique values to know if the changes have been made\n",
    "print(movie_df['Gross'].unique())\n",
    "\n",
    "print(movie_df['Gross'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **_Handling Duplicated Values_**\n",
    "\n",
    "Duplicated values can be handled in different ways, some might be tolerated depending on the columns they exist on and what type of data present there. for a data like this, the movies column is a unique identifier and should not be allowed to have duplicated values. Alright, so lets continue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i want to check for duplicates and remove duplicates for each column.\n",
    "#print the dataset\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the duplicated rows\n",
    "movie_df[movie_df.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates \n",
    "movie_df = movie_df.drop_duplicates(keep = 'first')\n",
    "#view the changes made in the dataframe\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#several rows have been dropped, but to ensure there are no duplicates, we check by the columns\n",
    "movie_df['MOVIES'].duplicated()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates by columns\n",
    "movie_df['MOVIES'] = movie_df['MOVIES'].drop_duplicates(keep = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicate\n",
    "movie_df['MOVIES'].duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i want to show the duplicated values in the column movies, for a closer look\n",
    "duplicate = movie_df[movie_df.duplicated(subset = 'MOVIES', keep = False)]\n",
    "duplicate\n",
    "#the movie title columns contain NaN, this is unacceptable as the column is a unique identifier and a major kpi to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i want to drop the NaN values from the dataset, but i would take a closer look before i do that\n",
    "movie_df['MOVIES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are definately NaN values there so i would drop them now. \n",
    "movie_df = movie_df.drop_duplicates(subset = 'MOVIES', keep = False)\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to see if the changes were okay\n",
    "movie_df['MOVIES'].duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next i want to round VOTES TO a whole munber\n",
    "movie_df['VOTES'].dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#then i want to round the runtime column to a whole number\n",
    "movie_df['RunTime'] = movie_df['RunTime'].round(0)\n",
    "movie_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Votes should be in int, not floats\n",
    "movie_df['VOTES'] = movie_df['VOTES'].astype('int64',errors='ignore')\n",
    "movie_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Runtime is also supposed to be in minutes, the right data type for that is int.\n",
    "movie_df['RunTime'] = movie_df['RunTime'].astype('int64', errors='ignore')\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Votes should be in int, not floats\n",
    "movie_df['VOTES'] = movie_df['VOTES'].astype('int64', errors='ignore')\n",
    "movie_df\n",
    "\n",
    "#Runtime is also supposed to be in minutes, the right data type for that is int.\n",
    "movie_df['RunTime'] = movie_df['RunTime'].astype('int64', errors='ignore')\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#that is a wrap. \n",
    "#what a journey that was!\n",
    "movie_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final desription of the data.\n",
    "movie_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final shape of the dataset\n",
    "movie_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final look at the dataset\n",
    "movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally, i would save the dataset to my desktop\n",
    "file_path = r'C:\\Users\\chhat\\Computer_Code/cleaned_movie_data.csv'\n",
    "movie_df.to_csv(file_path, index = False)\n",
    "#see you next time! caio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
